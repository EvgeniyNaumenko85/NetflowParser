package main

import (
	"NetflowParser/models"
	"NetflowParser/pkg"
	"NetflowParser/utilities"
	"fmt"
	"io"
	"os"
	"reflect"
	"runtime"
	"sync"
	"time"
)

func main() {
	f, _ := os.Create("cpu.prof")
	pprof.StartCPUProfile(f)
	defer pprof.StopCPUProfile()

	// Принимаем флаги из консоли
	filePath, NetFlowRecord, InputFields := pkg.AcceptFlagsFromConsole()

	// Выбираем функцию для парсинга
	funcNumber, err := utilities.SelectParseFuncNumb(InputFields)
	if err != nil {
		fmt.Println(err)
		return
	}

	// Открытие файла в режиме чтения
	file, err := pkg.OpenFileByFilePath(filePath)
	if err != nil {
		fmt.Println("Ошибка при открытии файла:", err)
		return
	}
	defer file.Close()

	// Пропуск двоичного заголовка файла (349 байт)
	headerSize := 349
	err = pkg.OmittingFileBinHeader(headerSize, file)
	if err != nil {
		fmt.Println("Ошибка при перемещении указателя файла:", err)
		return
	}

	// Количество горутин для параллельной обработки (зависит от количества ядер процессора)
	numWorkers := runtime.NumCPU()

	// Вычисляем размер части данных, которую будет обрабатывать каждая горутина
	fileInfo, err := file.Stat()
	if err != nil {
		fmt.Println("Ошибка при получении информации о файле:", err)
		return
	}
	fileSize := fileInfo.Size()
	partSize := fileSize / int64(numWorkers)

	// Канал для передачи количества найденных записей между горутинами и главной функцией
	counterChan := make(chan uint64, numWorkers)

	// Ограничитель для дожидания завершения всех горутин
	var wg sync.WaitGroup
	wg.Add(numWorkers)

	// Запускаем горутины-работники
	for i := 0; i < numWorkers; i++ {
		go processWorker(file, partSize, NetFlowRecord, &wg, counterChan, funcNumber)
	}

	// Дожидаемся завершения работы всех горутин
	wg.Wait()
	close(counterChan)

	// Создаем переменную для хранения общего количества найденных записей
	var counter uint64

	// Получаем общее количество найденных записей
	for val := range counterChan {
		counter += val
	}

	// ... Ваш текущий код ...

	fmt.Printf("\nНайдено  записей: %d со значениями:\n \tsource = %s\n \tdestination = %s\n \taccount_id = %d\n \ttclass = %d\n",
		counter, NetFlowRecord.Source.String(), NetFlowRecord.Destination.String(),
		utilities.BytesToUint32LE(NetFlowRecord.AccountID), utilities.BytesToUint32LE(NetFlowRecord.TClass))
	fmt.Printf("Прочитано %d записей за время %s\n", recordCount, elapsedTime)
	//fmt.Println("Number of goroutines:", numWorkers)
}

// Функция обработки данных для каждой горутины-работника
func processWorker(file *os.File, partSize int64, NetFlowRecord models.NetFlowRecord, wg *sync.WaitGroup, counterChan chan<- uint64, funcNumber int) {
	// Вычисляем начальную и конечную позиции для обработки данных
	startPos := int64(0)
	endPos := startPos + partSize

	// Последний воркер получает остаток данных
	if startPos+partSize >= fileSize {
		endPos = fileSize
	}

	// Изменяем позицию файла для текущей горутины
	file.Seek(startPos, io.SeekStart)

	// Читаем данные из файла для текущей горутины
	data := make([]byte, endPos-startPos)
	_, err := file.Read(data)
	if err != nil {
		fmt.Println("Ошибка при чтении данных из файла:", err)
		wg.Done()
		return
	}

	// Обработка данных на основе среза data с использованием выбранной функции
	switch funcNumber {
	case 1:
		// Функция для парсинга номера 1
		// ...
	case 2:
		// Функция для парсинга номера 2
		// ...
	}

	// Указываем WaitGroup, что работник закончил свою работу
	wg.Done()
}
